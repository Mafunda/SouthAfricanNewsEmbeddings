# -*- coding: utf-8 -*-
"""final_experients_for_the_paper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16ijhjaSeywqB9ItHC2LR1ggZZuVU7szo
"""

# Commented out IPython magic to ensure Python compatibility.
# This is needed to connect colab to the google drive of the polarization.project account
# You'll have to do this every 12 hours
from google.colab import drive
drive.mount('/content/drive', force_remount=False)

# This is needed to copy the latest version of our code from the github repo, where it is now maintained
# Navigate into the code folder
# %cd "/content/drive/My Drive/mma_word_embeddings/"
# Synchronise with latest github version
! git pull -f
# %cd ..

# This tells colab where our code files are
import sys
sys.path.append('/content/drive/My Drive/mma_word_embeddings/')

!pip install --upgrade gensim

!pip install xlsxwriter

from mma_word_embeddings.embedding import WordEmbedding

"""## '10p-200d-50m-Shuffled Similarity Values"""

# Commented out IPython magic to ensure Python compatibility.
from mma_word_embeddings.embedding import EmbeddingEnsemble
import pandas as pd
import random

path_to_embeddings = '/content/drive/My Drive/TRAINED_EMBEDDINGS/articles-big/'
import os
list_embeddings = [i[:len(i)-4] for i in os.listdir(path_to_embeddings) if (('.emb' in i) & (not '.vectors' in i) & (not 'constant' in i)& ('10p-200d-50m-' in i)) ==True] #
print(list_embeddings)
xyz = [random.sample(list_embeddings,3) for i in range(10) ]
print(xyz)
all_dfs = []
for i in xyz:
  result = EmbeddingEnsemble([path_to_embeddings+str(j)+'.emb' for j in i])
  df = result.score_similarity_test(full_output=True, rescale=False)
  all_dfs.append(df)
print(all_dfs[0].head())
xx = ['model{}-pred'.format(str(k+1)) for k in range(len(all_dfs))]
print(xx)
all_dfs2 = []
for i,j in zip(all_dfs,xx):
  df = i.rename(columns ={'prediction': str(j)})
  all_dfs2.append(df)
xx = [['{}-{}'.format(i,j) for i,j in zip(dfs.word1.tolist(),dfs.word2.tolist())] for dfs in all_dfs2]
aa_dfs_comb = []
for df,i in zip(all_dfs2,xx):
  df['combined']=i
  aa_dfs_comb.append(df[['combined','target']+[i for i in df.columns if '-pred' in i]])
'''
for i in aa_dfs_comb:
  print(i.head())

import matplotlib.pyplot as plt
plt.figure()
for i in aa_dfs_comb:
  plt.plot(range(i.shape[0]),i[[str(j) for j in i.columns if '-pred' in j]])
plt.show()
'''
aa_dfs_comb = [j[['combined','target','model%i-pred'%(i+1)]] for i,j in enumerate(aa_dfs_comb)]
from functools import reduce
df_final = reduce(lambda left,right: pd.merge(left,right,on='combined', how='inner'), aa_dfs_comb)
print(df_final.shape)

df_final = df_final[['combined', 'target_x', 'model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']]
df_final['mean'] =df_final[['model1-pred', 'model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']].mean(axis=1)
df_final['std'] =df_final[['model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']].std(axis=1)
df_final = df_final.drop_duplicates().reset_index()
df_final = df_final.sort_values(by='mean', ascending=False)
print(df_final.head())


import matplotlib.pyplot as plt
from datetime import datetime
f = datetime.now().strftime("%Y_%m_%d-%I_%M_%S_%p")
# %matplotlib inline
#writer = pd.ExcelWriter('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/sim_10p_shuffled_ensemble_result'+'.xlsx', engine='xlsxwriter') #+str(f)
#df_final.to_excel(writer, sheet_name='sim_10p_shuffled_ensemble', index=False)
#writer.save()
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale=1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11
fig, ax = plt.subplots()
fig.set_size_inches(10,6)
ax.set_facecolor('white')
x_range = range(df_final.shape[0])
ax.errorbar(x_range,df_final['mean'], label='Mean Similarity Value'.format(len(list_embeddings)),color='red', yerr=df_final['std'],ecolor='blue')
ax.legend(facecolor='white',frameon=False)
ax.set_ylabel('Similarity Value')
ax.set_xlabel('Word Pairs')
plt.grid(False)
#xx8[['target','mean']].plot(ax=ax, kind='bar')
#fig.savefig('/content/drive/My Drive/MARTIN_STUFF/VALIDATION/question_data/ensemble10p-200d-50m/sim_10p_shuffled_ensemble_result'+'.eps', bbox_inches="tight", dpi=1200)
fig.savefig('/content/drive/My Drive/MARTIN_STUFF/VALIDATION/final_graphs/sim_10p_shuffled_ensemble_result'+'.svg', bbox_inches="tight", dpi=1200)

print("Standard Deviation range:\n",df_final['std'].describe())

df_final['var'] = df_final['std']**2

df_final['var'].describe()

df_final.columns

tenP_shuffled_df = df_final[['combined','mean', 'std']]
tenP_shuffled_df.head()

"""## 10p-200d-50m-Constant : Similarity Values"""

# Commented out IPython magic to ensure Python compatibility.
from mma_word_embeddings.embedding import EmbeddingEnsemble
import pandas as pd

path_to_embeddings = '/content/drive/My Drive/TRAINED_EMBEDDINGS/articles-big/'
import os
list_embeddings = [i[:len(i)-4] for i in os.listdir(path_to_embeddings) if (('.emb' in i) & (not '.vectors' in i) & ('constant' in i)& ('10p-200d-50m-' in i)) ==True] #
print(list_embeddings)

xyz = [random.sample(list_embeddings,3) for i in range(10)]
print(xyz)
all_dfs = []
for i in xyz:
  result = EmbeddingEnsemble([path_to_embeddings+str(j)+'.emb' for j in i])
  df = result.score_similarity_test(full_output=True, rescale=False)
  all_dfs.append(df)
print(all_dfs[0].head())
xx = ['model{}-pred'.format(str(k+1)) for k in range(len(all_dfs))]
print(xx)
all_dfs2 = []
for i,j in zip(all_dfs,xx):
  df = i.rename(columns ={'prediction': str(j)})
  all_dfs2.append(df)
xx = [['{}-{}'.format(i,j) for i,j in zip(dfs.word1.tolist(),dfs.word2.tolist())] for dfs in all_dfs2]
aa_dfs_comb = []
for df,i in zip(all_dfs2,xx):
  df['combined']=i
  aa_dfs_comb.append(df[['combined','target']+[i for i in df.columns if '-pred' in i]])
'''
for i in aa_dfs_comb:
  print(i.head())

import matplotlib.pyplot as plt
plt.figure()
for i in aa_dfs_comb:
  plt.plot(range(i.shape[0]),i[[str(j) for j in i.columns if '-pred' in j]])
plt.show()
'''
aa_dfs_comb = [j[['combined','target','model%i-pred'%(i+1)]] for i,j in enumerate(aa_dfs_comb)]
from functools import reduce
df_final = reduce(lambda left,right: pd.merge(left,right,on='combined', how='inner'), aa_dfs_comb)
print(df_final.shape)

df_final = df_final[['combined', 'target_x', 'model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']]
df_final['mean'] =df_final[['model1-pred', 'model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']].mean(axis=1)
df_final['std'] =df_final[['model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']].std(axis=1)
df_final = df_final.drop_duplicates().reset_index()
df_final = df_final.sort_values(by='mean', ascending=False)
print(df_final.head())


import matplotlib.pyplot as plt
from datetime import datetime
f = datetime.now().strftime("%Y_%m_%d-%I_%M_%S_%p")
# %matplotlib inline
#writer = pd.ExcelWriter('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/sim_10p_shuffled_ensemble_result'+'.xlsx', engine='xlsxwriter') #+str(f)
#df_final.to_excel(writer, sheet_name='sim_10p_shuffled_ensemble', index=False)
#writer.save()
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale=1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11
fig, ax = plt.subplots()
fig.set_size_inches(10,6)
ax.set_facecolor('white')
x_range = range(df_final.shape[0])
ax.errorbar(x_range,df_final['mean'], label='Mean Similarity Value'.format(len(list_embeddings)),color='red', yerr=df_final['std'],ecolor='blue')
ax.legend(facecolor='white', frameon=False)
ax.set_ylabel('Similarity Value')
ax.set_xlabel('Word Pairs')
plt.grid(False)
#xx8[['target','mean']].plot(ax=ax, kind='bar')
#fig.savefig('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/sim_10p_constant_ensemble_result'+'.eps', bbox_inches="tight", dpi=1200)
fig.savefig('/content/drive/My Drive/MARTIN_STUFF/VALIDATION/final_graphs/sim_10p_constant_ensemble_result'+'.svg', bbox_inches="tight", dpi=1200)
print("Standard Deviation range:\n",df_final['std'].describe())

df_final['var'] = df_final['std']**2

df_final['var'].describe()

tenP_constant_df = df_final[['combined','mean', 'std']]
tenP_constant_df.head()

"""## 100p-300d-50m Whole Dataset"""

# Commented out IPython magic to ensure Python compatibility.
from mma_word_embeddings.embedding import EmbeddingEnsemble
import pandas as pd

path_to_embeddings = '/content/drive/My Drive/TRAINED_EMBEDDINGS/articles-big/'
import os
list_embeddings = [i[:len(i)-4] for i in os.listdir(path_to_embeddings) if (('.emb' in i) & (not '.vectors' in i) & (not 'constant' in i)& ('100p-300d-50m' in i)) ==True] #
print(list_embeddings)
import random

xyz = [random.sample(list_embeddings,3) for i in range(10)]
print(xyz)
all_dfs = []
for i in xyz:
  result = EmbeddingEnsemble([path_to_embeddings+str(j)+'.emb' for j in i])
  df = result.score_similarity_test(full_output=True, rescale=False)
  all_dfs.append(df)
print(all_dfs[0].head())
xx = ['model{}-pred'.format(str(k+1)) for k in range(len(all_dfs))]
print(xx)
all_dfs2 = []
for i,j in zip(all_dfs,xx):
  df = i.rename(columns ={'prediction': str(j)})
  all_dfs2.append(df)
xx = [['{}-{}'.format(i,j) for i,j in zip(dfs.word1.tolist(),dfs.word2.tolist())] for dfs in all_dfs2]
aa_dfs_comb = []
for df,i in zip(all_dfs2,xx):
  df['combined']=i
  aa_dfs_comb.append(df[['combined','target']+[i for i in df.columns if '-pred' in i]])

aa_dfs_comb = [j[['combined','target','model%i-pred'%(i+1)]] for i,j in enumerate(aa_dfs_comb)]
from functools import reduce
df_final = reduce(lambda left,right: pd.merge(left,right,on='combined', how='inner'), aa_dfs_comb)
print(df_final.shape)

df_final = df_final[['combined', 'target_x', 'model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']]
df_final['mean'] =df_final[['model1-pred', 'model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']].mean(axis=1)
df_final['std'] =df_final[['model1-pred', 'model2-pred','model3-pred','model4-pred','model5-pred','model6-pred', 'model7-pred','model8-pred','model9-pred','model10-pred']].std(axis=1)
df_final = df_final.drop_duplicates().reset_index()
df_final = df_final.sort_values(by='mean', ascending=False)
print(df_final.head())

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale=1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11
from datetime import datetime
f = datetime.now().strftime("%Y_%m_%d-%I_%M_%S_%p")
# %matplotlib inline
#writer = pd.ExcelWriter('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/sim_10p_shuffled_ensemble_result'+'.xlsx', engine='xlsxwriter') #+str(f)
#df_final.to_excel(writer, sheet_name='sim_10p_shuffled_ensemble', index=False)
#writer.save()
fig, ax = plt.subplots()
fig.set_size_inches(10,6)
ax.set_ylabel('Similarity Value')
ax.set_xlabel('Word Pairs')
ax.set_facecolor('white')
x_range = range(df_final.shape[0])
ax.errorbar(x_range,df_final['mean'], label='Mean Similarity Value'.format(len(list_embeddings)),color='red', yerr=df_final['std'],ecolor='blue')
ax.legend(facecolor='white', frameon=False, fontsize=11)
plt.grid(False)
#xx8[['target','mean']].plot(ax=ax, kind='bar')
#fig.savefig('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/sim_100p_ensemble_result'+'.eps', bbox_inches="tight", dpi=1200)
fig.savefig('/content/drive/My Drive/MARTIN_STUFF/VALIDATION/final_graphs/sim_100p_ensemble_result'+'.svg', bbox_inches="tight", dpi=1200)
print("Standard Deviation range:\n",df_final['std'].describe())

df_final['var'] = df_final['std']**2

df_final['var'].describe()

hundredp_shuffled_df = df_final[['combined','mean', 'std']]
hundredp_shuffled_df.head()

tenP_shuffled_df.shape, tenP_constant_df.shape, hundredp_shuffled_df.shape

merged1_df = pd.merge(left = tenP_shuffled_df, right = tenP_constant_df, on="combined")
merged2_df = pd.merge(left = merged1_df, right = hundredp_shuffled_df, on="combined")
merged2_df.head()

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
from matplotlib import style
style.use('bmh')
plt.rcParams['font.family'] = 'serif'
plt.rcParams['text.color'] = 'black'

fig, ax = plt.subplots()
fig.set_size_inches(10,6)
xx = range(merged2_df.shape[0])
ax.set_ylabel('Similarity')
ax.set_xlabel('Word Pairs')
ax.plot(xx, merged2_df['mean_x'], color='blue', label = '10p_shuffled')
ax.plot(xx, merged2_df['mean_y'], color='red', label = '10p_constant')
ax.plot(xx, merged2_df['mean'], color='green', label = 'whole dataset')
ax.legend()

# Commented out IPython magic to ensure Python compatibility.
'''
path_to_files = '/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'
my_file_names = ['sim_100p_ensemble_result','sim_10p__shuffled_ensemble_result','sim_10p_constant_ensemble_result']

excel_dfs = []
for i in my_file_names:
  df = pd.read_excel(path_to_files+str(i)+'.xlsx')
  excel_dfs.append(df.sort_values(by='combined'))

count =0
for i,j,k in zip(excel_dfs[0]['combined'].tolist(),excel_dfs[1]['combined'].tolist(),excel_dfs[2]['combined'].tolist()):
  if ((i ==j) & (j ==k)) ==True:
    count +=1

combined_dict = {'pair':excel_dfs[0]['combined'].tolist()}
for i,j in zip(excel_dfs,my_file_names):
  combined_dict['{}'.format(j)] = i['mean'].tolist()
my_sim_table = pd.DataFrame(combined_dict)
my_sim_table =my_sim_table.sort_values(by ='sim_100p_ensemble_result', ascending=False)

import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
from matplotlib import style
style.use('bmh')
plt.rcParams['font.family'] = 'serif'
plt.rcParams['text.color'] = 'black'

fig, ax = plt.subplots()
fig.set_size_inches(10,6)
xx = range(my_sim_table.shape[0])
ax.set_ylabel('Similarity')
ax.set_xlabel('Word Pairs')
ax.plot(xx, my_sim_table['sim_10p__shuffled_ensemble_result'], color='blue', label = '10p_shuffled')
ax.plot(xx, my_sim_table['sim_10p_constant_ensemble_result'], color='red', label = '10p_constant')
ax.plot(xx, my_sim_table['sim_100p_ensemble_result'], color='green', label = 'whole dataset')
ax.legend()
fig.savefig('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/sim_100p_shuffled_constant_ensemble_result'+str(f)+'.png')
'''

"""## Plotting analogy results on a singe plot"""

# Commented out IPython magic to ensure Python compatibility.
'''
least_squares_values = [0.23651920720697714,
 0.2724365740191528,
 0.2825205802227767,
 0.2847105821327939,
 0.2893971338366237,
 0.29294452725953535,
 0.30569180780169125,
 0.3043210008387418,
 0.304564016507084,
 0.3071969442397235]
import pandas as pd
path_to_excel = '/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'
#[i for i in os.listdir(path_to_excel) if '.xlsx' in i]
my_data200 = pd.read_excel(path_to_excel+'ensemble_result2021_05_13-04_05_12_AM.xlsx', sheet_name='Sheet2', index_col=0)

my_data200

import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
from matplotlib import style
style.use('bmh')
plt.rcParams['font.family'] = 'serif'
plt.rcParams['text.color'] = 'black'

fig, ax = plt.subplots()
fig.set_size_inches(10,6)

xx = range(my_data200.shape[0])
ax.set_ylabel('Analogy Precision')
ax.set_xlabel('Ensemble Size')
ax.plot(xx, my_data200['precision_value'], color='green', label = 'Precision')
ax.set_xticks([i for i in range(10)])
ax.set_xticklabels(my_data200.index)

ax1 = ax.twinx()
ax1.set_ylabel('Least Square Similarity Value')
#ax1.set_ylim(0.76,0.83)
ax1.plot(xx, least_squares_values, color = 'red', label ='Similarity')
fig.legend(loc = 'center', frameon = False)

fig.tight_layout()
'''

"""## 10p-200d-50m-Constant Dataset"""

# Commented out IPython magic to ensure Python compatibility.
'''
path_to_excel = '/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'
import os
file_names = [i for i in os.listdir(path_to_excel) if ('_con_' in i)]
print(file_names)
import pandas as pd
analogy_dict = {}
similarity_dict = {}
for i,j in enumerate(file_names):
  df = pd.read_excel('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'+str(j))
  #analogy_dict['Iteration_%i'%(i+1)] = df['precision_value']
  analogy_dict['Iteration_%i'%(i+1)] = df['precision_value']
  similarity_dict['Iteration_%i'%(i+1)] = df['least_sq_sim_value']
  #print(df)

analogy_df = pd.DataFrame(analogy_dict)
analogy_df['task'] = ['%iX'%(i+1) for i in range(analogy_df.shape[0])]
print(analogy_df.columns)

analogy_df['mean'] = analogy_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].mean(axis=1)
analogy_df['std'] = analogy_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].std(axis=1)
my_order = ['task']+['Iteration_%i'%(i+1) for i in range(7)]+['mean','std']
#print(analogy_df)
analogy_df[my_order].to_latex('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/analogy_constant.tex', index=False)

similarity_df = pd.DataFrame(similarity_dict)
similarity_df['task'] = ['%iX'%(i+1) for i in range(similarity_df.shape[0])]
#print(similarity_df)

similarity_df['mean'] = similarity_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].mean(axis =1)
similarity_df['std'] = similarity_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].std(axis =1)
#print(similarity_df)
similarity_df[my_order].to_latex('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/similarity_constant.tex', index=False)

import matplotlib.pyplot as plt
from datetime import datetime
f = datetime.now().strftime("%Y_%m_%d-%I_%M_%S_%p")
# %matplotlib inline
fig7,ax7 = plt.subplots()
ax7.set_ylabel('Precision(%)')
ax7.set_xlabel('Ensemble Size')
plt.errorbar(x = analogy_df.index, y = 'mean', data=analogy_df,color='red', yerr='std', ecolor='blue')
#analogy_df['mean'].plot(kind='line', ax = ax7)
ax7.set_xticks([i for i in range(10)])
ax7.set_xticklabels(analogy_df.task)
fig7.savefig('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/precision_10p_constant_ensemble_result'+'.png') #+str(f)
'''

"""## 10p-200d-50m-Shuffled Dataset"""

# Commented out IPython magic to ensure Python compatibility.
'''
path_to_excel = '/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'
import os
file_names = [i for i in os.listdir(path_to_excel) if (('_shuffled_' in i) & (not '.png' in i) & ('xlsx' in i) & (not 'sim' in i))]
print(file_names)

import pandas as pd
analogy_dict = {}
similarity_dict = {}
for i,j in enumerate(file_names):
  df = pd.read_excel('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'+str(j))
  analogy_dict['Iteration_%i'%(i+1)] = df['precision_value']
  similarity_dict['Iteration_%i'%(i+1)] = df['least_sq_sim_value']
  #print(df)

analogy_df = pd.DataFrame(analogy_dict)
analogy_df['task'] = ['%iX'%(i+1) for i in range(analogy_df.shape[0])]
#print(analogy_df)

analogy_df['mean'] = analogy_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].mean(axis=1)
analogy_df['std'] = analogy_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].std(axis=1)
my_order = ['task']+['Iteration_%i'%(i+1) for i in range(len(file_names))]+['mean','std']
print(analogy_df.columns)
analogy_df[my_order].to_latex('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/analogy_shuffled.tex', index=False)

similarity_df = pd.DataFrame(similarity_dict)
similarity_df['task'] = ['%iX'%(i+1) for i in range(similarity_df.shape[0])]
#print(similarity_df)

similarity_df['mean'] = similarity_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].mean(axis =1)
similarity_df['std'] = similarity_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].std(axis =1)
#print(similarity_df)
similarity_df[my_order].to_latex('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/similarity_shuffled.tex', index=False)

import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import style
plt.rcParams['font.family'] = 'serif'
# %matplotlib inline
style.use('bmh')
from datetime import datetime
f = datetime.now().strftime("%Y_%m_%d-%I_%M_%S_%p")
# %matplotlib inline
fig7,ax7 = plt.subplots()
ax7.set_ylabel('Precision(%)')
ax7.set_xlabel('Ensemble Size')
plt.errorbar(x = analogy_df.index, y = 'mean',data =analogy_df,color='red', yerr='std', ecolor='blue')
#analogy_df['mean'].plot(kind='line', ax = ax7)
ax7.set_xticks([i for i in range(10)])
ax7.set_xticklabels(analogy_df.task)
fig7.savefig('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/precision_10p_shuffled_ensemble_result'+'.png') #+str(f)
'''

# Commented out IPython magic to ensure Python compatibility.
'''
path_to_excel = '/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'
import os
file_names = [i for i in os.listdir(path_to_excel) if (('_100p_' in i) & (not '.png' in i) & ('xlsx' in i) & (not 'sim' in i))]
print(file_names)

import pandas as pd
analogy_dict = {}
similarity_dict = {}
for i,j in enumerate(file_names):
  df = pd.read_excel('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'+str(j))
  analogy_dict['Iteration_%i'%(i+1)] = df['precision_value']
  similarity_dict['Iteration_%i'%(i+1)] = df['least_sq_sim_value']
  #print(df)

analogy_df = pd.DataFrame(analogy_dict)
analogy_df['task'] = ['%iX'%(i+1) for i in range(analogy_df.shape[0])]
#print(analogy_df)

analogy_df['mean'] = analogy_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].mean(axis=1)
analogy_df['std'] = analogy_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].std(axis=1)
my_order = ['task']+['Iteration_%i'%(i+1) for i in range(len(file_names))]+['mean','std']
print(analogy_df.columns)
analogy_df[my_order].to_latex('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/analogy_100p.tex', index=False)

similarity_df = pd.DataFrame(similarity_dict)
similarity_df['task'] = ['%iX'%(i+1) for i in range(similarity_df.shape[0])]
#print(similarity_df)

similarity_df['mean'] = similarity_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].mean(axis =1)
similarity_df['std'] = similarity_df[['Iteration_%i'%(i+1) for i in range(len(file_names))]].std(axis =1)
#print(similarity_df)
similarity_df[my_order].to_latex('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/similarity_100p.tex', index=False)

import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import style
plt.rcParams['font.family'] = 'serif'
# %matplotlib inline
style.use('bmh')
from datetime import datetime
f = datetime.now().strftime("%Y_%m_%d-%I_%M_%S_%p")
# %matplotlib inline
fig7,ax7 = plt.subplots()
ax7.set_ylabel('Precision(%)')
ax7.set_xlabel('Ensemble Size')
plt.errorbar(x = analogy_df.index, y = 'mean',data =analogy_df, color ='red', yerr='std', ecolor='blue')
ax7.set_xticks([i for i in range(len(file_names))])
ax7.set_xticklabels(analogy_df.task)
fig7.savefig('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/precision_100p_ensemble_result'+'.png') #+str(f)
'''

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale=1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11

path_to_excel = '/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'

''' start of 100p - whole dataset'''
ensemble_100p_names = [i for i in os.listdir(path_to_excel) if (('_100p_' in i) & (not '.png' in i) & ('xlsx' in i) & (not 'sim' in i))]
ensemble_100p_dict = {}
for i,j in enumerate(ensemble_100p_names):
  df = pd.read_excel('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'+str(j))
  ensemble_100p_dict['Iteration_%i'%(i+1)] = df['precision_value']*100

ensemble_100p_df = pd.DataFrame(ensemble_100p_dict)
ensemble_100p_df['task'] = ['%iX'%(i+1) for i in range(ensemble_100p_df.shape[0])]
ensemble_100p_df['mean'] = ensemble_100p_df[['Iteration_%i'%(i+1) for i in range(len(ensemble_100p_names))]].mean(axis=1)
ensemble_100p_df['std'] = ensemble_100p_df[['Iteration_%i'%(i+1) for i in range(len(ensemble_100p_names))]].std(axis=1)
my_order = ['task']+['Iteration_%i'%(i+1) for i in range(len(ensemble_100p_names))]+['mean','std']
ensemble_100p_df = ensemble_100p_df[my_order]

''' start of 10p - shuffled subsample'''
ensemble_10p_shuffled_names = [i for i in os.listdir(path_to_excel) if (('_shuffled_' in i) & (not '.png' in i) & ('xlsx' in i) & (not 'sim' in i))]

ensemble_10p_shuffled_dict = {}

for i,j in enumerate(ensemble_10p_shuffled_names):
  df = pd.read_excel('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'+str(j))
  ensemble_10p_shuffled_dict['Iteration_%i'%(i+1)] = df['precision_value']*100

ensemble_10p_shuffled_df = pd.DataFrame(ensemble_10p_shuffled_dict)
ensemble_10p_shuffled_df['task'] = ['%iX'%(i+1) for i in range(ensemble_10p_shuffled_df.shape[0])]
#print(analogy_df)

ensemble_10p_shuffled_df['mean'] = ensemble_10p_shuffled_df[['Iteration_%i'%(i+1) for i in range(len(ensemble_10p_shuffled_names))]].mean(axis=1)
ensemble_10p_shuffled_df['std'] = ensemble_10p_shuffled_df[['Iteration_%i'%(i+1) for i in range(len(ensemble_10p_shuffled_names))]].std(axis=1)
my_order = ['task']+['Iteration_%i'%(i+1) for i in range(len(ensemble_10p_shuffled_names))]+['mean','std']
ensemble_10p_shuffled_df = ensemble_10p_shuffled_df[my_order]

''' start of 10p - constant subsample'''
ensemble_10p_constant_names = [i for i in os.listdir(path_to_excel) if ('_con_' in i)]

ensemble_10p_constant_dict = {}

for i,j in enumerate(ensemble_10p_constant_names):
  df = pd.read_excel('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/'+str(j))
  ensemble_10p_constant_dict['Iteration_%i'%(i+1)] = df['precision_value']*100

ensemble_10p_constant_df = pd.DataFrame(ensemble_10p_constant_dict)
ensemble_10p_constant_df['task'] = ['%iX'%(i+1) for i in range(ensemble_10p_constant_df.shape[0])]

ensemble_10p_constant_df['mean'] = ensemble_10p_constant_df[['Iteration_%i'%(i+1) for i in range(len(ensemble_10p_constant_names))]].mean(axis=1)
ensemble_10p_constant_df['std'] = ensemble_10p_constant_df[['Iteration_%i'%(i+1) for i in range(len(ensemble_10p_constant_names))]].std(axis=1)
my_order = ['task']+['Iteration_%i'%(i+1) for i in range(7)]+['mean','std']
ensemble_10p_constant_df = ensemble_10p_constant_df[my_order]
#print(analogy_df)
fig10, ax10 = plt.subplots()
fig10.set_size_inches(8,5)
plt.ylabel('Precision(%)') #fontdict={'fontsize':12}
plt.xlabel('Ensemble Size') #fontdict={'fontsize':12}
ax10.set_facecolor('white')
plt.errorbar(ensemble_10p_shuffled_df.index, ensemble_10p_shuffled_df['mean'],color='red',ls = '--', yerr=ensemble_10p_shuffled_df['std'], ecolor='blue', label='10p_shuffled')
plt.errorbar(ensemble_10p_shuffled_df.index, ensemble_10p_constant_df['mean'],color='purple',ls = '--', yerr=ensemble_10p_constant_df['std'], ecolor='blue',label='10p_constant')
plt.errorbar(ensemble_100p_df.index, ensemble_100p_df['mean'],color='green',ls = '--', yerr=ensemble_100p_df['std'], ecolor='blue',label='100p_whole dataset')
plt.legend(facecolor='white', frameon=False) #fontsize=12
ax10.set_xticks(ensemble_10p_shuffled_df.index)
ax10.set_xticklabels(ensemble_10p_shuffled_df.task, fontdict ={'fontsize':11})
ax10.set_yticklabels([int(i) for i in ax10.get_yticks()], fontdict ={'fontsize':11})
plt.grid(False)
plt.tight_layout()
fig10.savefig('/content/drive/My Drive/VALIDATION/final_graphs/precision_100p_shuffled_constant_ensemble'+'.eps',bbox_inches="tight", dpi=300) #+str(f)
fig10.savefig('/content/drive/My Drive/VALIDATION/final_graphs/precision_100p_shuffled_constant_ensemble'+'.svg',bbox_inches="tight", dpi=300)

"""#Plotting Sentences Vs Documents"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context = 'paper', font_scale = 1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11

my_dict = {
'tasks' : ['capital common countries','capital world','city in state','currency','family','adjective to adverb','opposite','comparative','superlative','present participle','nationality adjective', \
 'past tense','plural','plural verbs'],
'model_100p_200d_100m' : [i*100 for i in [0.98,0.95,0.69,0.38,0.81,0.63,0.48,0.95,0.76,0.86,0.96,0.89,0.83,0.8]],
'model_100p_docs_200d_100m' : [i*100 for i in [0.96, 0.94,0.68,0.38,0.78,0.6,0.43,0.89,0.62,0.85,0.97,0.87,0.85,0.74]]}

df = pd.DataFrame(my_dict).sort_values(by='model_100p_200d_100m', ascending = False).reset_index()
fig0,ax0 = plt.subplots()
fig0.set_size_inches(8,5)
ax0.set_ylabel('Analogy Task')
ax0.set_xlabel('Precision(%)')
ax0.set_facecolor('white')
ax0.plot(df['model_100p_200d_100m'], df.index, color = 'red',ls = '--', label = '100p-sentences-200d-100m',marker='D')
ax0.plot(df['model_100p_docs_200d_100m'],df.index, color = 'green',ls = '--', label = '100p-documents-200d-100m',marker='D')
ax0.legend(facecolor='white', frameon = False)
ax0.set_yticks(df.index)
ax0.set_yticklabels(df.index, fontsize = 11)
my_label = ['\n'.join(wrap(i,30)) for i in df.tasks.tolist()]
ax0.set_yticklabels(my_label, fontsize = 11)
ax0.set_xticks(ax0.get_xticks())
ax0.set_xticklabels([int(i) for i in ax0.get_xticks()],fontsize = 11)
plt.legend(fontsize = 11)
ax0.set_ylim(-0.2,13.5)
ax0.set_xlim(35,105)
plt.grid(False)
plt.tight_layout()
fig0.savefig('/content/drive/My Drive/VALIDATION/final_graphs/sentences_vs_documents'+'.eps', bbox_inches = "tight", dpi = 300)
fig0.savefig('/content/drive/My Drive/VALIDATION/final_graphs/sentences_vs_documents'+'.svg', bbox_inches = "tight", dpi = 300)

df = df.rename(columns={'model_100p_200d_100m':'100p-sentences-200d-100m', 'model_100p_docs_200d_100m':'100p-documents-200d-100m'})

df.columns

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context = 'paper', font_scale = 1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11
fig,ax = plt.subplots()
fig.set_size_inches(10,5)
ax.set_facecolor('white')
df[['tasks','100p-documents-200d-100m', '100p-sentences-200d-100m']].plot.bar(color=['green','red'], ax=ax)
ax.set_xticks([i for i in df.index])
ax.set_xticklabels(df.tasks, fontsize=11, rotation =90)
ax.set_yticklabels([int(i) for i in ax.get_yticks()], fontsize=11)
ax.legend(fontsize=11, frameon=False, facecolor='white')
plt.grid(False)
ax.set_xlabel("Analogy task")
ax.set_ylabel("Precision(%)")

fig.savefig('/content/drive/My Drive/VALIDATION/final_graphs/sentences_vs_documents'+'.svg', bbox_inches = "tight", dpi = 300)
fig.savefig('/content/drive/My Drive/VALIDATION/final_graphs/sentences_vs_documents'+'.eps', bbox_inches = "tight", dpi = 300)

"""## Min Word Count"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale = 1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11

min_word_count_dict  = {'tasks' : ['capital common countries','capital world','city in state','currency','family','adjective to adverb','opposite','comparative',\
                                  'superlative','present participle','nationality adjective','past tense','plural','plural verbs'],
                        'precision_5m' : [94,88,58,19,83,41,32,82,58,79,96,77,70,58],
                        'precision_10m' : [94,89,54,20,81,40,31,86,62,78,96,77,70,62],
                        'precision_50m' : [93,91,55,24,90,52,39,91,73,83,96,81,74,71],
                        'precision_100m' : [95,93,60,28,92,50,46,92,80,82,97,83,76,75]}


df_min = pd.DataFrame(min_word_count_dict).sort_values(by='precision_100m', ascending = False).reset_index()
fig00,ax00 = plt.subplots()
fig00.set_size_inches(8,5)
ax00.set_ylabel('Analogy Task')
ax00.set_xlabel('Precision(%)')
ax00.set_facecolor('white')
ax00.plot(df_min['precision_5m'], df_min.index,  color = 'red', label = '5m', ls = '--', marker='o')
ax00.plot(df_min['precision_10m'], df_min.index,  color = 'green', label = '10m',ls = '--', marker='o')
ax00.plot(df_min['precision_50m'], df_min.index,  color = 'blue', label = '50m',ls = '--', marker='o')
ax00.plot(df_min['precision_100m'], df_min.index,  color = 'purple', label = '100m',ls = '--', marker='o')
ax00.legend(facecolor='white', frameon = False)
ax00.set_yticks(df_min.index)
ax00.set_yticklabels(df_min.index, fontsize=11)
my_label = ['\n'.join(wrap(i,30)) for i in df_min.tasks.tolist()]
ax00.set_yticklabels(my_label, fontsize = 11)
ax00.set_xticks([int(i) for i in range(105) if i%10 ==0])
ax00.set_xticklabels([int(i) for i in range(105) if i%10 ==0],fontsize = 11)
plt.legend(fontsize=11)
ax00.set_ylim(-0.2,13.5)
ax00.set_xlim(15,105)
plt.grid(False)
#fig00.savefig('/content/drive/My Drive/VALIDATION/question_data/ensemble10p-200d-50m/min_word_count'+'.eps', bbox_inches="tight", dpi=1200)
fig00.savefig('/content/drive/My Drive/VALIDATION/final_graphs/min_word_count'+'.eps', bbox_inches="tight", dpi=300)
fig00.savefig('/content/drive/My Drive/VALIDATION/final_graphs/min_word_count'+'.svg', bbox_inches="tight", dpi=300)

df_min = df_min.rename(columns ={'precision_5m':'5m', 'precision_10m':'10m', 'precision_50m':'50m','precision_100m':'100m'})

df_min.columns

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale = 1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11
fig,ax = plt.subplots()
fig.set_size_inches(10,5)
ax.set_facecolor('white')
df_min[['tasks', '5m', '10m', '50m', '100m']].plot.bar(color=['green','red','blue','purple'], ax=ax)
ax.set_xticks([i for i in df_min.index])
ax.set_xticklabels(df_min.tasks, fontsize = 11, rotation = 90)
ax.set_yticklabels([int(i) for i in ax.get_yticks()], fontsize = 11)
ax.legend(fontsize = 11, frameon = False, facecolor = 'white')
plt.grid(False)
ax.set_xlabel("Analogy task")
ax.set_ylabel("Precision(%)")

fig.savefig('/content/drive/My Drive/VALIDATION/final_graphs/min_word_count'+'.svg', bbox_inches = "tight", dpi = 300)
fig.savefig('/content/drive/My Drive/VALIDATION/final_graphs/min_word_count'+'.eps', bbox_inches = "tight", dpi = 300)

"""## Hyperparameter Dimension"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale=1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11

hyper_dim_dict = {'tasks' : ['capital common countries','capital world','city in state','currency','family','adjective to adverb','opposite','comparative',\
                                  'superlative','present participle','nationality adjective','past tense','plural','plural verbs'],
                  'model_100p_100d_50m' : [i*100 for i in [0.98,0.93,0.58,0.35,0.76,0.58,0.35,0.82,0.59,0.81,0.93,0.83,0.71,0.64]],
                  'model_100p_200d_50m' : [i*100 for i in [0.98,0.95,0.67,0.39,0.80,0.63,0.46,0.94,0.74,0.86,0.95,0.89,0.80,0.77]],
                  'model_100p_300d_50m' : [i*100 for i in [0.99,0.96,0.72,0.37,0.85,0.65,0.49,0.96,0.77,0.88,0.94,0.92,0.85,0.80]],
                  'model_100p_400d_50m' : [i*100 for i in [0.99,0.96,0.73,0.37,0.86,0.65,0.48,0.97,0.79,0.88,0.95,0.93,0.87,0.83]]}


df_dim = pd.DataFrame(hyper_dim_dict).sort_values(by='model_100p_100d_50m', ascending = False).reset_index()
fig01,ax01 = plt.subplots()
fig01.set_size_inches(8,5)
ax01.set_ylabel('Analogy Task')
ax01.set_xlabel('Precision (%)')
ax01.set_facecolor('white')
ax01.plot(df_dim['model_100p_100d_50m'], df_dim.index,  color = 'red', label = '100p_100d_50m', ls = '--', marker='o')
ax01.plot(df_dim['model_100p_200d_50m'], df_dim.index,  color = 'green', label = '100p_200d_50m',ls = '--', marker='o')
ax01.plot(df_dim['model_100p_300d_50m'], df_dim.index,  color = 'blue', label = '100p_300d_50m',ls = '--', marker='o')
ax01.plot(df_dim['model_100p_400d_50m'], df_dim.index,  color = 'purple', label = '100p_400d_50m',ls = '--', marker='o')
ax01.legend(facecolor='white', frameon = False)
ax01.set_yticks(df_dim.index)
my_label = ['\n'.join(wrap(i,30)) for i in df_dim.tasks.tolist()]
ax01.set_yticklabels(my_label, fontsize = 11)
ax01.set_xticks([int(i) for i in range(105) if i%10 ==0])
ax01.set_xticklabels([int(i) for i in range(105) if i%10 ==0],fontsize = 11)
plt.legend(fontsize = 11)
ax01.set_ylim(-0.2,13.5)
ax01.set_xlim(15,105)
plt.grid(False)
plt.tight_layout()
fig01.savefig('/content/drive/My Drive/VALIDATION/final_graphs/hyper_dim'+'.eps', bbox_inches = "tight", dpi = 300)

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale=1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11
fig,ax = plt.subplots()
fig.set_size_inches(11,5)
ax.set_facecolor('white')
df_dim[['tasks', 'model_100p_100d_50m', 'model_100p_200d_50m','model_100p_300d_50m', 'model_100p_400d_50m']].plot.bar(color=['green','red','blue','purple'], ax=ax)
ax.set_xticks([i for i in df_dim.index])
ax.set_xticklabels(df_dim.tasks, fontsize = 11, rotation = 90)
ax.set_yticklabels([int(i) for i in ax.get_yticks()], fontsize = 11)
ax.legend(fontsize = 11, frameon=False, facecolor='white')
plt.grid(False)
ax.set_xlabel("Analogy task")
ax.set_ylabel("Precision(%)")

fig.savefig('/content/drive/My Drive/VALIDATION/final_graphs/hyper_dim'+'.svg', bbox_inches = "tight", dpi = 300)
fig.savefig('/content/drive/My Drive/VALIDATION/final_graphs/hyper_dim'+'.eps', bbox_inches = "tight", dpi = 300)

df_dim.columns

"""## Glove Vs Local"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale = 1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11

path_to_data = '/content/drive/My Drive/VALIDATION/question_data/glove_versus_local/results/'
file_names = [i for i in os.listdir(path_to_data) if '.xlsx' in i][:3]
print(file_names)

dfs = [pd.read_excel(path_to_data + str(i)).sort_values(by='task', ascending = True).reset_index() for i in file_names]
font_size = 20
fig01,ax01 = plt.subplots()
fig01.set_size_inches(8,6)
ax01.set_ylabel('Analogy Task', fontsize = font_size)
ax01.set_xlabel('Precision (%)', fontsize = font_size)
ax01.set_facecolor('white')
combined_df = pd.DataFrame({'task': dfs[0].task,
                            'local':dfs[0]['precision_value'].tolist(),
                            'glove':dfs[1]['precision_value'].tolist(),
                            'local_ensemble':dfs[2]['precision_value']})
combined_df = combined_df.sort_values(by='glove', ascending = False).reset_index()
ax01.plot(combined_df['local'], combined_df.index,  color = 'red', label = 'local', ls = '--', marker='D')
ax01.plot(combined_df['glove'], combined_df.index,  color = 'green', label = 'glove', ls = '--', marker='d')
ax01.plot(combined_df['local_ensemble'], combined_df.index,  color = 'blue', label = 'local ensemble', ls = '--', marker='H')
ax01.legend(facecolor='white', frameon = False)
labs = ['capital common countries', 'capital world', 'plural', 'nationality adjective', 'family', 'comparative', 'superlative', 'plural verbs', 'present participle',\
        'past tense', 'city in state', 'adjective to adverb', 'opposite', 'currency']

ax01.set_yticks(combined_df.index)
my_label = ['\n'.join(wrap(i,30)) for i in labs]
ax01.set_yticklabels(my_label, fontsize = font_size)
ax01.set_xticks([int(i) for i in range(105) if i%25 ==0])
ax01.set_xticklabels([int(i) for i in range(105) if i%25 ==0],fontsize = font_size)
plt.legend(loc ='lower left', fontsize = font_size, frameon=False, facecolor='white')
ax01.set_ylim(-0.2,13.5)
ax01.set_xlim(30,105)
plt.grid(False)
plt.tight_layout()
fig01.savefig('/content/drive/My Drive/VALIDATION/final_graphs/local_v_glove_1'+'.svg', bbox_inches = "tight", dpi = 300)

combined_df.columns

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale = 1.5)
from matplotlib import style
from textwrap import wrap
import os
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11

fig,ax = plt.subplots()
fig.set_size_inches(10,5)
ax.set_facecolor('white')
combined_df[['task', 'local', 'glove', 'local_ensemble']].plot.bar(color=['green','red','blue'], ax=ax)
ax.set_xticks([i for i in df_dim.index])
ax.set_xticklabels(df_dim.tasks, fontsize = 11, rotation = 90)
ax.set_yticklabels(ax.get_yticks(), fontsize = 11)
ax.legend(fontsize = 11, frameon = False, facecolor = 'white')
plt.grid(False)
ax.set_xlabel("Analogy task")
ax.set_ylabel("Precision(%)")
fig.savefig('/content/drive/My Drive/VALIDATION/final_graphs/local_v_glove'+'.svg', bbox_inches = "tight", dpi = 300)
fig.savefig('/content/drive/My Drive/VALIDATION/final_graphs/local_v_glove'+'.eps', bbox_inches = "tight", dpi = 300)

combined_df['id'] = combined_df.index
combined_df = combined_df.rename(columns={'local':'A1', 'glove':'A2', 'local_ensemble':'A3'}) #'local':'A1', 'glove':'A2', 'local_ensemble':'A3'
combined_df

new_comb_df = pd.wide_to_long(combined_df, i='id', j='model', stubnames=['A']).reset_index()
new_comb_df

!pip install pingouin

import pingouin as pg

new_comb_df.task.unique()



for t in new_comb_df.task.unique():
  kk = new_comb_df[new_comb_df['task']==t]['A'].tolist()
  i = 0
  xx = []
  for i in range(len(kk)):
    for j in range(len(kk)):
      if i < j:
        xx.append([kk[i],kk[j]])
  from math import sqrt
  def test(x,y):
    import numpy as np
    return np.abs(x-y)/sqrt(x+y)
  print(t,'\n',[test(x=i[0],y=i[1]) for i in xx],'\n',xx)



"""## Local Evaluations"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_context(context='paper',font_scale=1.5)
from matplotlib import style
from textwrap import wrap
style.use('bmh')
# %matplotlib inline
plt.rcParams['font.family'] ='serif'
plt.rcParams['text.color'] = 'black'
plt.rcParams['font.size'] = 11

path_to_data = '/content/drive/My Drive/VALIDATION/train_n_evaluate/localw2v_eval_local_data_2021_06_02-10_39_38_AM.xlsx'
df = pd.read_excel(path_to_data)
df = df.iloc[1:,]
print(df)
fig01,ax01 = plt.subplots()
fig01.set_size_inches(5,5)
ax01.set_xlabel('Analogy Task')
ax01.set_ylabel('Precision (%)')
ax01.set_facecolor('white')
ax01.bar(df.index, df['precision_value'], color = 'blue', width=0.5)
labs = ['South African political party - politician','South African province - city']
ax01.set_xticks(df.index)
my_label = ['\n'.join(wrap(i,15)) for i in labs]
ax01.set_xticklabels(my_label, fontsize=11)
ax01.set_yticks(ax01.get_yticks())
ax01.set_yticklabels([int(i) for i in ax01.get_yticks()], fontsize=11)
ax01.set_xlim(0.5,2.6)
ax01.set_ylim(0,105)
plt.grid(False)
for i,j in enumerate(df.precision_value):
  plt.text(i+1-0.05,j+0.02,''+str(int(j))+'%', fontsize = 11)
fig01.savefig('/content/drive/My Drive/VALIDATION/final_graphs/local'+'.eps', bbox_inches="tight", dpi=300)
fig01.savefig('/content/drive/My Drive/VALIDATION/final_graphs/local'+'.svg', bbox_inches="tight", dpi=300)

dfs[0].task.tolist()

from mma_word_embeddings.embedding import WordEmbedding

import os
file_path = '/content/drive/My Drive/TRAINED_EMBEDDINGS/articles-big/'
constant = [i for i in os.listdir(file_path) if (('.emb' in i) & (not '.vectors' in i) &('constant' in i))]
em = [WordEmbedding(file_path+str(i)) for i in constant]
em_sizes = [i.vocab_size() for i in em]
print(em_sizes)